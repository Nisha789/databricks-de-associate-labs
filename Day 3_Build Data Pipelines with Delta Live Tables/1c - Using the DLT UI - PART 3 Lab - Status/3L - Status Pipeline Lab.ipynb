{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7478f313-f19f-45aa-9e1e-c5c5503c730d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "263b2e63-d143-4d16-b0a2-ba6b45112528",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Troubleshooting DLT SQL Syntax\n",
    "\n",
    "Now that we've gone through the process of configuring and running a pipeline with 2 notebooks, we'll simulate developing and adding a 3rd notebook.\n",
    "\n",
    "**DON'T PANIC!** Things are about to break.\n",
    "\n",
    "The code provided below contains some intentional, small syntax errors. By troubleshooting these errors, you'll learn how to iteratively develop DLT code and identify errors in your syntax.\n",
    "\n",
    "This lesson is not meant to provide a robust solution for code development and testing; rather, it is intended to help users getting started with DLT and struggling with an unfamiliar syntax.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this lesson, students should feel comfortable:\n",
    "* Identifying and troubleshooting DLT syntax \n",
    "* Iteratively developing DLT pipelines with notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d401f938-3433-4c4b-a980-883f101b8931",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## A. Add this Notebook to a DLT Pipeline\n",
    "\n",
    "At this point in the course, you should have a DLT Pipeline configured with 2 notebook libraries.\n",
    "\n",
    "You should have processed several batches of records through this pipeline, and should understand how to trigger a new run of the pipeline and add an additional library.\n",
    "\n",
    "To begin this lesson, go through the process of adding this notebook to your pipeline using the DLT UI, and then trigger an update.\n",
    "\n",
    "**NOTE** Must follow the steps in the first two notebooks to configure the DLT pipeline prior to this lab.\n",
    "  - [1a - Using the DLT UI - PART 1 - Orders]($../1a - Using the DLT UI - PART 1 - Orders)\n",
    "  - [1b - Using the DLT UI - PART 2 - Customers]($../1b - Using the DLT UI - PART 2 - Customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f483f31-ad51-41fc-8c4d-b8e7a4265184",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## B. Complete the Following to Troubleshooting DLT Errors\n",
    "\n",
    "Each of the 3 queries below contains a syntax error, but each of these errors will be detected and reported slightly differently by DLT.\n",
    "\n",
    "**NOTES**:\n",
    "\n",
    "- Some syntax errors will be detected during the **Initializing** stage, as DLT is not able to properly parse the commands.\n",
    "\n",
    "- Other syntax errors will be detected during the **Setting up tables** stage.\n",
    "\n",
    "- Note that because of the way DLT resolves the order of tables in the pipeline at different steps, you may sometimes see errors thrown for later stages first.\n",
    "\n",
    "- An approach that can work well is to fix one table at a time, starting at your earliest dataset and working toward your final. Commented code will be ignored automatically, so you can safely remove code from a development run without removing it entirely.\n",
    "\n",
    "- Even if you can immediately spot the errors in the code below, try to use the error messages from the UI to guide your identification of these errors. Solution code follows in the cell below.\n",
    "\n",
    "**COMPLETE THE FOLLOWING**\n",
    "1. In *Query 1* create a streaming table.\n",
    "\n",
    "2. In *Query 2* create a streaming table and make sure to reference the **status_bronze** streaming table correctly in the `FROM` clause.\n",
    "\n",
    "3. In *Query 3* create a materialized view and make sure to reference the **status_silver** streaming table correctly in the `FROM` clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2cf18339-8ced-4eec-9af4-d32db0ccb6ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "-- Query 1\n",
    "CREATE OR REFRESH STREAMING TABLE status_bronze     -- Fill in code to create or refresh a streaming table\n",
    "AS \n",
    "SELECT \n",
    "  current_timestamp() AS processing_time, \n",
    "  *\n",
    "FROM cloud_files(\"${source}/status\", \"json\");\n",
    "\n",
    "\n",
    "-- Query 2\n",
    "CREATE OR REFRESH STREAMING TABLE status_silver     -- Fill in code to create or refresh a streaming table\n",
    "  (CONSTRAINT valid_timestamp EXPECT (status_timestamp > 1640600000) ON VIOLATION DROP ROW)\n",
    "AS \n",
    "SELECT * EXCEPT (_rescued_data)\n",
    "FROM STREAM(LIVE.status_bronze);     -- Fix the FROM clause to reference a the status_bronze streaming table  \n",
    "\n",
    "\n",
    "-- Query 3\n",
    "CREATE OR REFRESH MATERIALIZED VIEW email_updates     -- Fill in code to create or refresh a streaming materialized view\n",
    "AS \n",
    "SELECT a.*, b.email\n",
    "FROM LIVE.status_silver a    -- Fix the FROM clause to reference the status_silver streaming table\n",
    "INNER JOIN LIVE.subscribed_order_emails_v b\n",
    "ON a.order_id = b.order_id;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c63a354-96f6-4e91-92aa-0bd60fcc3144",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### LAB HINTS\n",
    "The issues in each query:\n",
    "1. (Query 1) The **`CREATE OR REFRESH STREAMING TABLE`** keyword is missing from the create statement.\n",
    "\n",
    "2. (Query 2) The **`CREATE OR REFRESH STREAMING TABLE`** keyword is missing from the create statement and **`STREAM(LIVE.status_bronze)`** is missing in the from clause.\n",
    "\n",
    "3. (Query 3) The **`LIVE`** keyword is missing from the **status_silver** table referenced by the from clause: **`LIVE.status_silver`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48887597-a189-40e5-afbc-3f049c4523de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## C. Solutions\n",
    "\n",
    "The correct syntax for each of our above functions is provided in a notebook by the same name in the Solutions folder.\n",
    "\n",
    "To address these errors you have several options:\n",
    "* Work through each issue, fixing the problems above yourself\n",
    "* Copy and paste the solution in the **`# ANSWER`** cell from the Solutions notebook of the same name\n",
    "* Update your pipline to directly use the Solutions notebook of the same name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0cd9024-345e-4e6e-bf4b-bc722ab98938",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "By reviewing this notebook, you should now feel comfortable:\n",
    "* Identifying and troubleshooting DLT syntax \n",
    "* Iteratively developing DLT pipelines with notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b8d21f2-2531-4b50-ad03-c0d473343e94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "&copy; 2025 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/><a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | \n",
    "<a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | \n",
    "<a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3L - Status Pipeline Lab",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}